"""
å°†å†å²æ‘˜è¦å‘é‡å†™å…¥ Chromaï¼ˆçº¯ Chroma æ¨¡å¼è¡¥å½•è„šæœ¬ï¼‰

ç”¨æ³•ï¼š
    PYTHONPATH=. conda run -n echoman python backend/scripts/backfill_chroma_summaries.py

è¯´æ˜ï¼š
    - ä»…å†™å…¥ Chromaï¼Œä¸ä¾èµ– pgvectorã€‚
    - ä½¿ç”¨æ‰¹å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§è¯·æ±‚è¿‡å¤§ã€‚
    - é‡‡ç”¨ upsertï¼Œé‡å¤è¿è¡Œä¹Ÿä¸ä¼šæŠ¥é”™ï¼ˆä¼šè¦†ç›–å·²æœ‰åŒ ID çš„è®°å½•ï¼‰ã€‚
"""
import asyncio
from typing import List

from sqlalchemy import select, func

from app.core.database import get_async_session
from app.models import Summary
from app.services.llm import get_embedding_provider
from app.services.vector_service import get_vector_service


BATCH_SIZE = 32  # å•æ‰¹å¤„ç†æ•°é‡ï¼Œå¯æŒ‰éœ€è¦è°ƒæ•´


async def fetch_summaries(session, offset: int, limit: int) -> List[Summary]:
    stmt = (
        select(Summary)
        .order_by(Summary.id)
        .offset(offset)
        .limit(limit)
    )
    result = await session.execute(stmt)
    return result.scalars().all()


async def main():
    vector_service = get_vector_service()
    if vector_service.db_type != "chroma" or not vector_service.collection:
        raise RuntimeError("Chroma æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¡¥å†™æ‘˜è¦å‘é‡")

    embedding_provider = get_embedding_provider()

    session_maker = get_async_session()
    async with session_maker() as session:
        total = (
            await session.execute(select(func.count()).select_from(Summary))
        ).scalar_one()
        print(f"ğŸ”¢ å¾…å¤„ç†æ‘˜è¦æ€»æ•°: {total}")

        processed = 0
        offset = 0

        while offset < total:
            summaries = await fetch_summaries(session, offset, BATCH_SIZE)
            if not summaries:
                break

            texts = [s.content for s in summaries]
            vectors = await embedding_provider.embedding(texts)

            ids = [f"topic_summary_{s.id}" for s in summaries]
            metadatas = [
                {
                    "object_type": "topic_summary",
                    "object_id": int(s.id),
                    "topic_id": int(s.topic_id),
                    "generated_at": s.generated_at.timestamp() if s.generated_at else None,
                }
                for s in summaries
            ]
            documents = [text[:500] for text in texts]

            # é‡‡ç”¨ upsertï¼Œé¿å…é‡å¤æŠ¥é”™
            vector_service.collection.upsert(
                ids=ids,
                embeddings=vectors,
                metadatas=metadatas,
                documents=documents,
            )

            processed += len(summaries)
            offset += len(summaries)
            print(f"âœ… å·²å†™å…¥ {processed}/{total}")

    stats = vector_service.get_collection_stats()
    print(f"ğŸ“Š å®Œæˆï¼Œå½“å‰ Chroma è®¡æ•°: {stats}")


if __name__ == "__main__":
    asyncio.run(main())
