"""
å‘é‡æ£€ç´¢ä¼˜åŒ–æœåŠ¡

æä¾›pgvectorç´¢å¼•ç®¡ç†å’Œä¼˜åŒ–åŠŸèƒ½
"""
from typing import Optional, List, Dict
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
from app.config import settings


class VectorOptimizationService:
    """å‘é‡æ£€ç´¢ä¼˜åŒ–æœåŠ¡"""
    
    def __init__(self):
        self.settings = settings
        
    async def create_ivfflat_index(
        self,
        db: AsyncSession,
        table_name: str = "embeddings",
        column_name: str = "vector",
        lists: Optional[int] = None,
        index_name: Optional[str] = None
    ) -> Dict:
        """
        åˆ›å»ºIVFFlatç´¢å¼•
        
        IVFFlatç´¢å¼•ä½¿ç”¨å€’æ’æ–‡ä»¶ï¼ˆinverted fileï¼‰åŠ é€Ÿå‘é‡æ£€ç´¢
        é€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®é›†ï¼ˆ>10ä¸‡æ¡å‘é‡ï¼‰
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            table_name: è¡¨å
            column_name: å‘é‡åˆ—å
            lists: èšç±»ä¸­å¿ƒæ•°é‡ï¼ˆé»˜è®¤ä¸ºè¡Œæ•°çš„å¹³æ–¹æ ¹ï¼‰
            index_name: ç´¢å¼•åç§°
            
        Returns:
            ç´¢å¼•åˆ›å»ºç»“æœ
        """
        # ç¡®å®šlistså‚æ•°
        if lists is None:
            # æ¨èå€¼ï¼šå¯¹äº N è¡Œæ•°æ®ï¼Œä½¿ç”¨ sqrt(N) æˆ– N/1000
            count_stmt = text(f"SELECT COUNT(*) FROM {table_name}")
            result = await db.execute(count_stmt)
            row_count = result.scalar()
            
            if row_count > 1000000:
                lists = int(row_count / 1000)
            elif row_count > 100000:
                lists = int(row_count ** 0.5)
            else:
                lists = 100  # å°æ•°æ®é›†ä½¿ç”¨é»˜è®¤å€¼
        
        # ç¡®å®šç´¢å¼•åç§°
        if index_name is None:
            index_name = f"{table_name}_{column_name}_ivfflat_idx"
        
        # åˆ›å»ºç´¢å¼•SQL
        create_index_sql = text(f"""
            CREATE INDEX IF NOT EXISTS {index_name}
            ON {table_name}
            USING ivfflat ({column_name} vector_cosine_ops)
            WITH (lists = {lists})
        """)
        
        try:
            print(f"ğŸ”§ å¼€å§‹åˆ›å»ºIVFFlatç´¢å¼•...")
            print(f"   è¡¨å: {table_name}")
            print(f"   åˆ—å: {column_name}")
            print(f"   lists: {lists}")
            
            await db.execute(create_index_sql)
            await db.commit()
            
            print(f"âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ: {index_name}")
            
            return {
                "status": "success",
                "index_name": index_name,
                "lists": lists,
                "table_name": table_name
            }
            
        except Exception as e:
            print(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
            await db.rollback()
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def create_hnsw_index(
        self,
        db: AsyncSession,
        table_name: str = "embeddings",
        column_name: str = "vector",
        m: int = 16,
        ef_construction: int = 64,
        index_name: Optional[str] = None
    ) -> Dict:
        """
        åˆ›å»ºHNSWç´¢å¼•
        
        HNSWï¼ˆHierarchical Navigable Small Worldï¼‰ç´¢å¼•
        æä¾›æ›´é«˜çš„æŸ¥è¯¢æ€§èƒ½ï¼Œä½†æ„å»ºæ—¶é—´è¾ƒé•¿
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            table_name: è¡¨å
            column_name: å‘é‡åˆ—å
            m: æ¯å±‚çš„æœ€å¤§è¿æ¥æ•°ï¼ˆé»˜è®¤16ï¼‰
            ef_construction: æ„å»ºæ—¶çš„æœç´¢å€™é€‰æ•°ï¼ˆé»˜è®¤64ï¼‰
            index_name: ç´¢å¼•åç§°
            
        Returns:
            ç´¢å¼•åˆ›å»ºç»“æœ
        """
        if index_name is None:
            index_name = f"{table_name}_{column_name}_hnsw_idx"
        
        create_index_sql = text(f"""
            CREATE INDEX IF NOT EXISTS {index_name}
            ON {table_name}
            USING hnsw ({column_name} vector_cosine_ops)
            WITH (m = {m}, ef_construction = {ef_construction})
        """)
        
        try:
            print(f"ğŸ”§ å¼€å§‹åˆ›å»ºHNSWç´¢å¼•...")
            print(f"   è¡¨å: {table_name}")
            print(f"   m: {m}")
            print(f"   ef_construction: {ef_construction}")
            
            await db.execute(create_index_sql)
            await db.commit()
            
            print(f"âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ: {index_name}")
            
            return {
                "status": "success",
                "index_name": index_name,
                "m": m,
                "ef_construction": ef_construction
            }
            
        except Exception as e:
            print(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
            await db.rollback()
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def optimize_query_performance(
        self,
        db: AsyncSession,
        probes: int = 10
    ):
        """
        ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
        
        è®¾ç½®æŸ¥è¯¢æ—¶çš„æ¢æµ‹æ•°é‡ï¼ˆprobesï¼‰
        æ›´å¤šprobes = æ›´é«˜å‡†ç¡®ç‡ï¼Œæ›´æ…¢é€Ÿåº¦
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            probes: æ¢æµ‹æ•°é‡ï¼ˆé»˜è®¤10ï¼ŒèŒƒå›´1-listsï¼‰
        """
        set_probes_sql = text(f"SET ivfflat.probes = {probes}")
        await db.execute(set_probes_sql)
        
        print(f"âœ… è®¾ç½®æŸ¥è¯¢æ¢æµ‹æ•°: {probes}")
    
    async def analyze_index_usage(
        self,
        db: AsyncSession,
        table_name: str = "embeddings"
    ) -> Dict:
        """
        åˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            table_name: è¡¨å
            
        Returns:
            ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
        """
        # æŸ¥è¯¢è¡¨çš„ç´¢å¼•ä¿¡æ¯
        index_info_sql = text(f"""
            SELECT 
                indexname,
                indexdef
            FROM pg_indexes
            WHERE tablename = '{table_name}'
            AND indexname LIKE '%vector%'
        """)
        
        result = await db.execute(index_info_sql)
        indexes = result.fetchall()
        
        # æŸ¥è¯¢è¡¨ç»Ÿè®¡
        stats_sql = text(f"""
            SELECT 
                COUNT(*) as total_rows,
                pg_size_pretty(pg_total_relation_size('{table_name}')) as table_size
            FROM {table_name}
        """)
        
        stats_result = await db.execute(stats_sql)
        stats = stats_result.fetchone()
        
        return {
            "table_name": table_name,
            "total_rows": stats[0] if stats else 0,
            "table_size": stats[1] if stats else "æœªçŸ¥",
            "indexes": [
                {"name": idx[0], "definition": idx[1]}
                for idx in indexes
            ]
        }
    
    async def vacuum_analyze(
        self,
        db: AsyncSession,
        table_name: str = "embeddings"
    ):
        """
        æ‰§è¡ŒVACUUM ANALYZEä¼˜åŒ–è¡¨
        
        å®šæœŸæ‰§è¡Œä»¥ä¿æŒç´¢å¼•æ€§èƒ½
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            table_name: è¡¨å
        """
        try:
            # æ³¨æ„ï¼šVACUUMä¸èƒ½åœ¨äº‹åŠ¡ä¸­æ‰§è¡Œ
            # éœ€è¦ä½¿ç”¨autocommitæ¨¡å¼
            await db.connection(execution_options={"isolation_level": "AUTOCOMMIT"})
            
            vacuum_sql = text(f"VACUUM ANALYZE {table_name}")
            await db.execute(vacuum_sql)
            
            print(f"âœ… VACUUM ANALYZEå®Œæˆ: {table_name}")
            
        except Exception as e:
            print(f"âš ï¸  VACUUM ANALYZEå¤±è´¥: {e}")
    
    async def drop_index(
        self,
        db: AsyncSession,
        index_name: str
    ):
        """
        åˆ é™¤ç´¢å¼•
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            index_name: ç´¢å¼•åç§°
        """
        drop_sql = text(f"DROP INDEX IF EXISTS {index_name}")
        
        try:
            await db.execute(drop_sql)
            await db.commit()
            print(f"âœ… ç´¢å¼•å·²åˆ é™¤: {index_name}")
            
        except Exception as e:
            print(f"âŒ åˆ é™¤ç´¢å¼•å¤±è´¥: {e}")
            await db.rollback()
    
    async def benchmark_query(
        self,
        db: AsyncSession,
        query_vector: List[float],
        k: int = 10,
        table_name: str = "embeddings"
    ) -> Dict:
        """
        æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            query_vector: æŸ¥è¯¢å‘é‡
            k: è¿”å›Top-Kç»“æœ
            table_name: è¡¨å
            
        Returns:
            æ€§èƒ½ç»Ÿè®¡
        """
        import time
        
        # æ„é€ æŸ¥è¯¢å‘é‡å­—ç¬¦ä¸²
        vector_str = f"[{','.join(map(str, query_vector))}]"
        
        # å¯ç”¨æŸ¥è¯¢è®¡åˆ’åˆ†æ
        explain_sql = text(f"""
            EXPLAIN ANALYZE
            SELECT id, vector <=> '{vector_str}'::vector AS distance
            FROM {table_name}
            ORDER BY distance
            LIMIT {k}
        """)
        
        start_time = time.time()
        result = await db.execute(explain_sql)
        query_plan = result.fetchall()
        elapsed_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        return {
            "query_time_ms": round(elapsed_time, 2),
            "top_k": k,
            "query_plan": [row[0] for row in query_plan]
        }


# æä¾›ä¾¿æ·çš„ç´¢å¼•åˆå§‹åŒ–å‡½æ•°
async def initialize_vector_indexes(db: AsyncSession):
    """
    åˆå§‹åŒ–æ‰€æœ‰å‘é‡ç´¢å¼•
    
    å»ºè®®åœ¨æ•°æ®å¯¼å…¥åæ‰§è¡Œ
    """
    service = VectorOptimizationService()
    
    print("ğŸš€ å¼€å§‹åˆå§‹åŒ–å‘é‡ç´¢å¼•...")
    
    # ä¸ºembeddingsè¡¨åˆ›å»ºIVFFlatç´¢å¼•
    result = await service.create_ivfflat_index(
        db,
        table_name="embeddings",
        column_name="vector"
    )
    
    if result["status"] == "success":
        print("âœ… å‘é‡ç´¢å¼•åˆå§‹åŒ–å®Œæˆ")
    else:
        print(f"âŒ å‘é‡ç´¢å¼•åˆå§‹åŒ–å¤±è´¥: {result.get('error')}")
    
    # åˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ
    stats = await service.analyze_index_usage(db)
    print(f"\nğŸ“Š ç´¢å¼•ç»Ÿè®¡:")
    print(f"   æ€»è¡Œæ•°: {stats['total_rows']}")
    print(f"   è¡¨å¤§å°: {stats['table_size']}")
    print(f"   ç´¢å¼•æ•°: {len(stats['indexes'])}")

